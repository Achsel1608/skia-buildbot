#!/usr/bin/env python
# Copyright (c) 2012 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

"""Archives or replays webpages and creates skps in a Google Storage location.

To archive webpages and store skp files (will be run rarely to update archives):

cd ../buildbot/slave/skia_slave_scripts
python webpages_playback.py --dest_gsbase=gs://rmistry --record=True \
--page_sets=all --debugger=~/trunk/out/Release/debugger \
--browser_executable=~/chromium/out/Release/chrome


To replay archived webpages and re-generate skp files (should be run whenever
SkPicture.PICTURE_VERSION changes):

cd ../buildbot/slave/skia_slave_scripts
python webpages_playback.py --dest_gsbase=gs://rmistry --record=False \
--page_sets=all --debugger=~/trunk/out/Release/debugger \
--browser_executable=~/chromium/out/Release/chrome


Specify the --page_sets flag (default value is 'all') to pick a list of which
webpages should be archived and/or replayed. Eg:

--page_sets=page_sets/skia_yahooanswers_desktop.json,\
page_sets/skia_wikipedia_galaxynexus.json

The --browser_executable flag should point to the browser binary you want to use
to capture archives and/or capture SKP files. Majority of the time it should be
a newly built chrome binary. Please make sure that proxies are turned off in the
binary.

The --upload_to_gs flag controls whether generated artifacts will be uploaded
to Google Storage (default value is 'False').

The --debugger flag if specified will allow you to preview the captured skp
before proceeding to the next page_set. It needs to point to a pre-built
debugger. Eg: trunk/out/Release/debugger

"""

import glob
import json
import optparse
import os
import posixpath
import shutil
import sys
import tempfile
import time
import traceback


# Set the PYTHONPATH for this script to include chromium_buildbot scripts,
# and site_config.
sys.path.append(
    os.path.join(os.pardir, os.pardir, 'third_party', 'chromium_buildbot',
                 'scripts'))
sys.path.append(
    os.path.join(os.pardir, os.pardir, 'third_party', 'chromium_buildbot',
                 'site_config'))


from slave import slave_utils
from slave import svn
from utils import file_utils
from utils import gs_utils
from utils import shell_utils

from build_step import PLAYBACK_CANNED_ACL
from playback_dirs import ROOT_PLAYBACK_DIR_NAME
from playback_dirs import SKPICTURES_DIR_NAME


# Local archive and skp directories.
LOCAL_PLAYBACK_ROOT_DIR = os.path.join(
    tempfile.gettempdir(), ROOT_PLAYBACK_DIR_NAME)
LOCAL_REPLAY_WEBPAGES_ARCHIVE_DIR = os.path.join(
    os.path.abspath(os.path.dirname(__file__)), 'page_sets', 'data')
TMP_SKP_DIR = tempfile.mkdtemp()

# Location of Telemetry binaries (record_wpr, run_measurement).
TELEMETRY_BINARIES_DIR = os.path.join(
    os.path.dirname(__file__), os.pardir, os.pardir, 'third_party',
    'chromium_trunk', 'tools', 'perf'
)

# Location of the credentials.json file and the string that represents missing
# passwords.
CREDENTIALS_FILE_PATH = os.path.join(
    os.path.dirname(__file__), 'page_sets', 'data', 'credentials.json'
)
CREDENTIALS_MISSING_PASSWORD = '***'

# Stdout that signifies that a recording has failed.
RECORD_FAILURE_MSG = 'The recording has not been updated for these pages.'

# Name of the SKP benchmark
SKP_BENCHMARK = 'skpicture_printer'

# The max base name length of Skp files.
MAX_SKP_BASE_NAME_LEN = 31

# Dictionary of device to platform prefixes for skp files.
DEVICE_TO_PLATFORM_PREFIX = {
    'desktop': 'desk',
    'galaxynexus': 'mobi',
    'nexus10': 'tabl'
}


class SkPicturePlayback(object):
  """Class that archives or replays webpages and creates skps."""

  def __init__(self, parse_options):
    """Constructs a SkPicturePlayback BuildStep instance."""
    assert parse_options.browser_executable, 'Must specify --browser_executable'
    self._browser_executable = parse_options.browser_executable

    self._all_page_sets_specified = parse_options.page_sets == 'all'
    self._page_sets = self._ParsePageSets(parse_options.page_sets)

    self._dest_gsbase = parse_options.dest_gsbase
    self._record = parse_options.record == 'True'
    self._debugger = parse_options.debugger
    self._upload_to_gs = parse_options.upload_to_gs == 'True'

    self._local_skp_dir = os.path.join(
        parse_options.output_dir, ROOT_PLAYBACK_DIR_NAME, SKPICTURES_DIR_NAME)
    self._local_record_webpages_archive_dir = os.path.join(
        parse_options.output_dir, ROOT_PLAYBACK_DIR_NAME, 'webpages_archive')

    self._trunk = parse_options.trunk
    self._svn_username = parse_options.svn_username
    self._svn_password = parse_options.svn_password

    # List of skp files generated by this script.
    self._skp_files = []

  def _ParsePageSets(self, page_sets):
    if not page_sets:
      raise ValueError('Must specify atleast one page_set!')
    elif self._all_page_sets_specified:
      # Get everything from the page_sets directory.
      return [os.path.join('page_sets', page_set)
              for page_set in os.listdir('page_sets')
              if not os.path.isdir(os.path.join('page_sets', page_set))]
    elif '*' in page_sets:
      # Explode and return the glob.
      return glob.glob(page_sets)
    else:
      return page_sets.split(',')

  def Run(self):
    """Run the SkPicturePlayback BuildStep."""

    # Ensure that the credentials.json file has been edited.
    with open(CREDENTIALS_FILE_PATH, 'r') as credentials_file:
      parsed_json = json.load(credentials_file)
      for key in parsed_json:
        if parsed_json[key]["password"] == CREDENTIALS_MISSING_PASSWORD:
          raise Exception("Please enter the correct password for %s in %s" % (
                              key, CREDENTIALS_FILE_PATH))

    # Ensure the right .boto file is used by gsutil.
    if self._upload_to_gs and not (
            gs_utils.DoesStorageObjectExist(self._dest_gsbase)):
      raise Exception(
          'Missing .boto file or .boto does not have the right credentials.'
          'Please see https://docs.google.com/a/google.com/document/d/1ZzHP6M5q'
          'ACA9nJnLqOZr2Hl0rjYqE4yQsQWAfVjKCzs/edit '
          '(may have to request access)')

    # Delete any left over data files in the data directory.
    for archive_file in glob.glob(
        os.path.join(LOCAL_REPLAY_WEBPAGES_ARCHIVE_DIR, 'skia_*')):
      os.remove(archive_file)

    # Delete the local root directory if it already exists.
    if os.path.exists(LOCAL_PLAYBACK_ROOT_DIR):
      shutil.rmtree(LOCAL_PLAYBACK_ROOT_DIR)

    # Create the required local storage directories.
    self._CreateLocalStorageDirs()

    # Start the timer.
    start_time = time.time()

    # Loop through all page_sets.
    for page_set in self._page_sets:

      page_set_basename = os.path.basename(page_set)
      wpr_data_file = page_set.split(os.path.sep)[-1].split('.')[0] + '_000.wpr'
      # Get some properties from the page_set JSON.
      with open(page_set, 'r') as page_set_file:
        parsed_json = json.load(page_set_file)
        skp_layer = parsed_json.get('skp_layer', 'layer_0.skp')

      if self._record:
        # Create an archive of the specified webpages if '--record=True' is
        # specified.
        record_wpr_cmd = (
          os.path.join(TELEMETRY_BINARIES_DIR, 'record_wpr'),
          '--extra-browser-args=--disable-setuid-sandbox',
          '--browser=exact',
          '--browser-executable=%s' % self._browser_executable,
          page_set
        )
        retry = True
        while retry:
          output = shell_utils.Bash(record_wpr_cmd)
          retry = False
          if RECORD_FAILURE_MSG in output:
            user_input = raw_input(
                "Would you like to rerun record_wpr? [y,n]")
            if user_input == 'y':
              retry = True
            else:
              raise Exception(output)
      else:
        # Get the webpages archive so that it can be replayed.
        self._DownloadWebpagesArchive(wpr_data_file, page_set_basename)

      accept_skp = False
      while not accept_skp:
        run_measurement_cmd = (
            os.path.join(TELEMETRY_BINARIES_DIR, 'run_measurement'),
            '--extra-browser-args=--disable-setuid-sandbox',
            '--browser=exact',
            '--browser-executable=%s' % self._browser_executable,
            SKP_BENCHMARK,
            page_set,
            '-o',
            '/tmp/test.skp',
            '--skp-outdir=%s' % TMP_SKP_DIR
        )
        retry = True
        while retry:
          try:
            shell_utils.Bash(run_measurement_cmd)
            retry = False
          except Exception, e:
            traceback.print_exc()
            user_input = raw_input(
              "Would you like to retry the skp? [y,n]")
            if user_input != 'y':
              raise e

        if self._debugger:
          skp_files = glob.glob(os.path.join(TMP_SKP_DIR, '*', skp_layer))
          for skp_file in skp_files:
            os.system('%s %s' % (self._debugger, skp_file))
          user_input = raw_input(
              "Would you like to recapture the skp(s)? [y,n]")
          accept_skp = False if user_input == 'y' else True
        else:
          # Always accept skps if debugger is not provided to preview.
          accept_skp = True

      if self._record:
        # Move over the created archive into the local webpages archive
        # directory.
        shutil.move(
            os.path.join(LOCAL_REPLAY_WEBPAGES_ARCHIVE_DIR, wpr_data_file),
            self._local_record_webpages_archive_dir)
        shutil.move(
            os.path.join(LOCAL_REPLAY_WEBPAGES_ARCHIVE_DIR, page_set_basename),
            self._local_record_webpages_archive_dir)

      # Rename generated skp files into more descriptive names.
      self._RenameSkpFiles(page_set, skp_layer)

    print '\n\n=======Capturing SKP files took %s seconds=======\n\n' % (
        time.time() - start_time)

    if self._upload_to_gs:
      # Copy the directory structure in the root directory into Google Storage.
      gs_status = slave_utils.GSUtilCopyDir(
          src_dir=LOCAL_PLAYBACK_ROOT_DIR, gs_base=self._dest_gsbase,
          dest_dir=ROOT_PLAYBACK_DIR_NAME, gs_acl=PLAYBACK_CANNED_ACL)
      if gs_status != 0:
        raise Exception(
            'ERROR: GSUtilCopyDir error %d. "%s" -> "%s/%s"' % (
                gs_status, LOCAL_PLAYBACK_ROOT_DIR, self._dest_gsbase,
                ROOT_PLAYBACK_DIR_NAME))
    
      # Add a timestamp file to the skp directory in Google Storage so we can
      # use directory level rsync like functionality.
      gs_utils.WriteTimeStampFile(
          timestamp_file_name=gs_utils.TIMESTAMP_COMPLETED_FILENAME,
          timestamp_value=time.time(),
          gs_base=self._dest_gsbase,
          gs_relative_dir=posixpath.join(ROOT_PLAYBACK_DIR_NAME,
                                         SKPICTURES_DIR_NAME),
          gs_acl=PLAYBACK_CANNED_ACL,
          local_dir=LOCAL_PLAYBACK_ROOT_DIR)

      # Submit a whitespace change if all required arguments have been provided.
      if self._trunk and self._svn_username and self._svn_password:
        repo = svn.Svn(self._trunk, self._svn_username, self._svn_password,
                       additional_svn_flags=[
                           '--trust-server-cert', '--no-auth-cache',
                           '--non-interactive'])
        whitespace_file = open(
            os.path.join(self._trunk, 'whitespace.txt'), 'a')
        try:
          whitespace_file.write('\n')
        finally:
          whitespace_file.close()
        if self._all_page_sets_specified:
          commit_msg = 'All skp files in Google Storage have been updated'
        else:
          commit_msg = (
              'Updated the following skp files on Google Storage: %s' % (
                  self._skp_files))
        # Adding a pattern that makes the commit msg show up as an annotation
        # in the dashboard. Please see for more details:
        # https://code.google.com/p/skia/issues/detail?id=1065
        commit_msg += ' (AddDashboardAnnotation)'
        # pylint: disable=W0212
        repo._RunSvnCommand(
            ['commit', '--message', commit_msg, 'whitespace.txt'])

    return 0

  def _RenameSkpFiles(self, page_set, skp_layer):
    """Rename generated skp files into more descriptive names.

    All skp files are currently called layer_X.skp where X is an integer, they
    will be renamed into http_website_name.skp.

    Eg: http_news_yahoo_com/layer_0.skp -> http_news_yahoo_com.skp
    """
    for (dirpath, _dirnames, filenames) in os.walk(TMP_SKP_DIR):
      if not dirpath or not filenames:
        continue
      basename = os.path.basename(dirpath)
      for filename in filenames:
        if filename != skp_layer:
          continue
        filename_parts = filename.split('.')
        extension = filename_parts[1]
        basename = basename.rstrip('_')

        # Gets the platform prefix for the page set.
        # Eg: for 'skia_yahooanswers_desktop.json' it gets 'desktop'.
        device = (page_set.split(os.path.sep)[-1].split('_')[-1].split('.')[0])
        platform_prefix = DEVICE_TO_PLATFORM_PREFIX[device]
        # Gets the webpage name from the page set name.
        # Eg: for 'skia_yahooanswers_desktop.json' it gets 'yahooanswers'.
        webpage_name = page_set.split(os.path.sep)[-1].split('_')[-2]

        # Construct the basename of the skp file.
        basename = '%s_%s' % (platform_prefix, webpage_name)

        # Ensure the basename is not too long.
        if len(basename) > MAX_SKP_BASE_NAME_LEN:
          basename = basename[0:MAX_SKP_BASE_NAME_LEN]
        new_filename = '%s.%s' % (basename, extension)
        shutil.move(os.path.join(dirpath, filename),
                    os.path.join(self._local_skp_dir, new_filename))
        self._skp_files.append(new_filename)
      shutil.rmtree(dirpath)

  def _CreateLocalStorageDirs(self):
    """Creates required local storage directories for this script."""
    file_utils.CreateCleanLocalDir(self._local_record_webpages_archive_dir)
    file_utils.CreateCleanLocalDir(self._local_skp_dir)

  def _DownloadWebpagesArchive(self, wpr_data_file, page_set_basename):
    """Downloads the webpages archive and its required page set from GS."""
    wpr_source = posixpath.join(
        self._dest_gsbase, ROOT_PLAYBACK_DIR_NAME, 'webpages_archive',
        wpr_data_file)
    page_set_source = posixpath.join(
        self._dest_gsbase, ROOT_PLAYBACK_DIR_NAME, 'webpages_archive',
        page_set_basename)
    if (gs_utils.DoesStorageObjectExist(wpr_source) and
        gs_utils.DoesStorageObjectExist(page_set_source)):
      slave_utils.GSUtilDownloadFile(
          src=wpr_source, dst=LOCAL_REPLAY_WEBPAGES_ARCHIVE_DIR)
      slave_utils.GSUtilDownloadFile(
          src=page_set_source, dst=LOCAL_REPLAY_WEBPAGES_ARCHIVE_DIR)
    else:
      raise Exception('%s and %s do not exist in Google Storage!' % (
          wpr_source, page_set_source))


if '__main__' == __name__:
  option_parser = optparse.OptionParser()
  option_parser.add_option(
      '', '--page_sets',
      help='Specifies the page sets to use to archive. Supports globs.',
      default='all')
  option_parser.add_option(
      '', '--record',
      help='Specifies whether a new website archive should be created.',
      default='False')
  option_parser.add_option(
      '', '--dest_gsbase',
      help='gs:// bucket_name, the bucket to upload the file to.',
      default='gs://chromium-skia-gm')
  option_parser.add_option(
      '', '--debugger',
      help=('Path to a debugger. You can preview a captured skp if a debugger '
            'is specified.'),
      default=None)
  option_parser.add_option(
      '', '--upload_to_gs',
      help='Does not upload to Google Storage if this is False.',
      default='False')
  option_parser.add_option(
      '', '--output_dir',
      help='Directory where SKPs and webpage archives will be outputted to.',
      default=tempfile.gettempdir())
  option_parser.add_option(
      '', '--trunk',
      help='Path to Skia trunk, used for whitespace commit.',
      default=None)
  option_parser.add_option(
      '', '--svn_username',
      help='SVN username, used for whitespace commit.',
      default=None)
  option_parser.add_option(
      '', '--svn_password',
      help='SVN password, used for whitespace commit.',
      default=None)
  option_parser.add_option(
      '', '--browser_executable',
      help='The exact browser executable to run.',
      default=None)
  options, unused_args = option_parser.parse_args()

  playback = SkPicturePlayback(options)
  sys.exit(playback.Run())
