# General
ALERT InstanceDown
  IF up == 0
  FOR 5m
  LABELS { category = "infra", severity = "critical" }
  ANNOTATIONS {
    summary = "Instance {{ $labels.instance }} down",
    description = "{{ $labels.instance }} of job {{ $labels.job }} has been down for more than 5 minutes.",
  }

ALERT TooManyGoRoutines
  IF go_goroutines > 3000
  FOR 2m
  LABELS { category = "infra", severity = "warning"}
  ANNOTATIONS {
    summary = "Too many Go routines in {{ $labels.job }}",
    description = "Too many Go routines in {{ $labels.job }} running on {{ $labels.instance }}."
  }

ALERT ProbeFailure
  IF prober{type="failure"} > 0
  FOR 5m
  LABELS { category = "infra", severity = "critical" }
  ANNOTATIONS {
    summary = "Probe failed {{ $labels.probename }}",
    description = "Endpoint {{ $labels.probename }} has failed to respond in at least 5 minutes. See https://github.com/google/skia-buildbot/search?q={{ $labels.probename }}+filename%3Aprobers.json for the endpoint URL."
  }

ALERT RebootRequired
  IF reboot_required_i > 0
  LABELS { category = "infra", severity = "warning" }
  ANNOTATIONS {
    description = "Instance {{ $labels.host }} needs rebooting. Owner(s): {{ $labels.owners }}. See https://mon.skia.org/dashboard/db/reboots-required for the full list of instances that need rebooting.",
  }

ALERT DiskSpaceLow
  IF df_complex_free{resource="df-root",host!~".*rpi-.+"} < 1e9
  FOR 5m
  LABELS { category = "infra", severity = "warning" }
  ANNOTATIONS {
    description = "Low Root Disk Space on {{ $labels.host }}.",
  }

ALERT DiskSpaceLow
  IF df_complex_free{resource=~"df-mnt-pd0|df-mnt-dds0"} < 1e10
  FOR 5m
  LABELS { category = "infra", severity = "warning" }
  ANNOTATIONS {
    description = "Low Disk Space on {{ $labels.host }} on disk {{ $labels.resource }}.",
  }

ALERT DiskSpaceLow
  IF df_complex_free{resource="df-b",host!~".*rpi-.+"} < 2e10
  FOR 5m
  LABELS { category = "infra", severity = "warning" }
  ANNOTATIONS {
    description = "Free space has fallen below 20GB on {{ $labels.host }} drive {{ $labels.resource }}.\n\nTry running:\ngo run scripts/run_on_swarming_bots/run_on_swarming_bots.go --alsologtostderr --script=scripts/run_on_swarming_bots/delete_out_dirs.py --dimension id:{{ $labels.host }}",
  }

ALERT DiskSpaceLow
  IF df_complex_free{resource=~"df-var|df-tmp",host=~"skia-rpi-.+"} < 1e8
  FOR 5m
  LABELS { category = "infra", severity = "warning" }
  ANNOTATIONS {
    description = "Free space has fallen below 100MB on {{ $labels.host }} drive {{ $labels.resource}}.",
  }

# CT
ALERT CTPollerHealthCheck
  IF healthy{instance="skia-ct-master:20000",job="ct-poller"} != 1
  FOR 5m
  LABELS { category = "infra", severity = "critical" }
  ANNOTATIONS {
    summary = "CT poller healthy check failed.",
    description = "CT poller health check is failing. https://skia.googlesource.com/buildbot/+/master/ct/PROD.md#ct_poller_health_check."
  }

ALERT CTFEPendingTaskCount
  IF num_pending_tasks{instance="skia-ctfe:20000",job="ctfe"} >= 10
  FOR 5m
  LABELS { category = "infra", severity = "critical" }
  ANNOTATIONS {
    summary = "CTFE pending task count too high.",
    description = "There are a lot of CTFE pending tasks. https://skia.googlesource.com/buildbot/+/master/ct/PROD.md#ctfe_pending_tasks"
  }

ALERT CTFEPendingTaskStatus
  IF oldest_pending_task_status{instance="skia-ctfe:20000",job="ctfe"} >= 2
  FOR 5m
  LABELS { category = "infra", severity = "critical" }
  ANNOTATIONS {
    summary = "CTFE pending task not running.",
    description = "A task has been waiting to be executed for a while and it's still not started. https://skia.googlesource.com/buildbot/+/master/ct/PROD.md#ctfe_pending_tasks"
  }

ALERT CTFEErrorRate
  IF rate(num_log_lines{level="ERROR",log_source="ctfe"}[2m]) > 0.1
  FOR 2m
  LABELS { category = "infra", severity = "critical" }
  ANNOTATIONS {
    summary = "CTFE error rate too high.",
    description = "The error rate for CTFE is too high. See cloud logging for skia-ctfe."
  }

# Perf
ALERT PerfUntriagedClusters
  IF perf_clustering_untriaged{instance="skia-perf:20000"} > 0
  LABELS { category = "general", severity = "warning" }
  ANNOTATIONS {
    summary = "One or more untriaged clusters.",
    description = "At least one untriaged perf cluster has been found. Please visit https://perf.skia.org/t/ to triage."
  }

ALERT AndroidPerfUntriagedClusters
  IF perf_clustering_untriaged{instance="skia-android-perf:20000"} > 0
  LABELS { category = "general", severity = "warning", specialroute = "android" }
  ANNOTATIONS {
    summary = "One or more untriaged clusters.",
    description = "At least one untriaged perf cluster has been found. Please visit https://android-perf.skia.org/t/ to triage."
  }

ALERT AndroidIngestFailures
  IF rate(process_failures[2m]) > 0.1
  LABELS { category = "infra", severity = "critical" }
  ANNOTATIONS {
    description = "Error rate for processing buildids is too high. See https://github.com/google/skia-buildbot/blob/master/android_ingest/PROD.md#process_failures."
  }

ALERT PerfIngestErrorTooHigh
  IF rate(ingestion{metric="errors"}[5m]) > 1
  LABELS { category = "infra", severity = "critical" }
  ANNOTATIONS {
    description = "Perf ingestion error rate too high. See https://prom.skia.org/graph?g0.range_input=1h&g0.expr=rate(ingestion%7Bmetric%3D%22errors%22%7D%5B5m%5D)&g0.tab=0"
  }

# For fiddle, debugger, and imageinfo.

ALERT BuildsFailed
  IF builds_failed >= 2
  LABELS { category = "infra", severity = "warning" }
  ANNOTATIONS {
    description = "Build for {{ $labels.job }} has failed for the last 2 chrome DEPS rolls. https://skia.googlesource.com/buildbot/+/master/{{ $labels.job }}/PROD.md#build_fail"
  }

ALERT SyncFailed
  IF repo_sync_failed >= 2
  LABELS { category = "infra", severity = "warning" }
  ANNOTATIONS {
    description = "Sync for {{ $labels.job }} has failed 2 times in a row. https://skia.googlesource.com/buildbot/+/master/{{ $labels.job }}/PROD.md#sync_fail"
  }

ALERT NamedFiddles
  IF named_failures > 0
  LABELS { category = "infra", severity = "warning" }
  ANNOTATIONS {
    description = "See https://fiddle.skia.org/f/ and https://skia.googlesource.com/buildbot/+/master/fiddle/PROD.md#named_fail"
  }

# datahopper_internal

ALERT Google3AutorollStalled
  IF datahopper_internal_ingest_build_webhook_oldest_untested_commit_age/60/60 > 3
  LABELS { category = "infra", severity = "warning" }
  ANNOTATIONS {
    description = "Commit has not been picked up by Google3-Autoroller for over three hours. https://sites.google.com/a/google.com/skia-infrastructure/docs/google3-autoroller."
  }

ALERT DatahopperInternalUpdateWebhookMetrics
  IF liveness_ingest_build_webhook_oldest_untested_commit_age_metric_s/60 > 10
  LABELS { category = "infra", severity = "warning" }
  ANNOTATIONS {
    description = "datahopper_internal goroutine for updateWebhookMetrics is dead or failing."
  }

ALERT TooManyGoRoutines
  IF go_goroutines{instance="skia-internal:20000",job="datahopper_internal"} > 100
  FOR 2m
  LABELS { category = "infra", severity = "warning"}
  ANNOTATIONS {
    description = "Too many Go routines in {{ $labels.job }} running on {{ $labels.instance }}."
  }

# Swarming

ALERT BotMissing
  IF swarming_bots_last_seen/1024/1024/1024/60 > 15
  LABELS { category = "infra", severity = "critical"}
  ANNOTATIONS {
    description = "Swarming bot {{ $labels.bot }} is missing. https://chromium-swarm.appspot.com/bot?id={{ $labels.bot }} https://goto.google.com/skolo-maintenance"
  }

ALERT BotQuarantined
  IF swarming_bots_quarantined == 1
  FOR 10m
  LABELS { category = "infra", severity = "critical"}
  ANNOTATIONS {
    description = "Swarming bot {{ $labels.bot }} is quarantined. https://chromium-swarm.appspot.com/bot?id={{ $labels.bot }} https://goto.google.com/skolo-maintenance"
  }

